{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#爬取新聞並變成csv檔\n",
    "#概念就是，當我們網頁往下滾到底部後，會觸發網頁的 JavaScript 程式，讓它透過 Ajax 動態載入，將新聞資料一直載入進來，所以這也是動態爬蟲的一種情況。\n",
    "#這裡我們使用 requests 模組來發送請求，並使用 requests.get() 方法來發送 GET 請求，然後使用 response.json() 方法來解析返回的 JSON 資料。\n",
    "import requests\n",
    "import time\n",
    "\n",
    "page_num = 23  # 設定要爬取的頁數，經過實測，一天新聞的量大約需請求23頁\n",
    "\n",
    "def get_news_list(page_num):\n",
    "    \"\"\"爬取新聞列表\"\"\"\n",
    "    base_url = \"https://udn.com/api/more\"  # 修正後的 base_url\n",
    "\n",
    "    news_list = []\n",
    "    for page in range(page_num):\n",
    "        channelId = 1\n",
    "        cate_id = 0\n",
    "        type_ = 'breaknews'\n",
    "        query = f\"page={page+1}&channelId={channelId}&cate_id={cate_id}&type={type_}\"\n",
    "        news_list_url = base_url + '?' + query\n",
    "        print(news_list_url)\n",
    "        \n",
    "        try:\n",
    "            # 使用 requests 發起請求\n",
    "            response = requests.get(news_list_url)\n",
    "            response.raise_for_status()  # 檢查請求是否成功\n",
    "            data = response.json()  # 解析返回的 JSON 資料\n",
    "            news_list.extend(data.get('lists', []))  # 假設新聞列表在 'lists' 鍵中\n",
    "        except requests.RequestException as e:\n",
    "            print(f\"請求第 {page+1} 頁時出錯: {e}\")\n",
    "            print(\"請檢查網頁連結的合法性，並確保網路連線正常。\")\n",
    "            print(\"如果問題仍然存在，可以稍後重試。\")\n",
    "            break  # 如果請求失敗，退出循環\n",
    "\n",
    "    return news_list\n",
    "\n",
    "# 調用函數獲取新聞列表\n",
    "news_list = get_news_list(page_num)\n",
    "print(news_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#生成dataframe\n",
    "import pandas as pd\n",
    "# 將 JSON 數據轉換為 DataFrame\n",
    "df = pd.DataFrame(news_list)\n",
    "\n",
    "# 提取所有標題，並將缺失值（NaN）排除\n",
    "text = \" \".join(df['title'].dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#生成文字雲所需之套件\n",
    "import jieba\n",
    "import numpy as np\n",
    "from wordcloud import WordCloud\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定義停用詞\n",
    "stopwords = \"\"\"的\n",
    "了\n",
    "在\n",
    "是\n",
    "我\n",
    "有\n",
    "和\n",
    "不\n",
    "人\n",
    "都\n",
    "一\n",
    "對\n",
    "說\n",
    "要\n",
    "來\n",
    "這\n",
    "他\n",
    "也\n",
    "為\n",
    "以\n",
    "上\n",
    "下\n",
    "為什麼\n",
    "所以\n",
    "那\n",
    "把\n",
    "它\n",
    "你\n",
    "她\n",
    "我們的\n",
    "他們\n",
    "他們的\n",
    "來自\n",
    "可以\n",
    "去\n",
    "這些\n",
    "會\n",
    "還\n",
    "的\n",
    "為了\n",
    "如果\n",
    "但\n",
    "之後\n",
    "當\n",
    "會\n",
    "此\n",
    "其\n",
    "從\n",
    "等\n",
    "更多\n",
    "因\n",
    "己\n",
    "後\n",
    "變\n",
    "與\n",
    "又\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#生成文字雲圖片\n",
    "# 將停用詞保存到文件\n",
    "with open(\"stopwords.txt\", \"w\", encoding=\"utf-8\") as file:\n",
    "    file.write(stopwords.strip())\n",
    "\n",
    "# 加載停用詞\n",
    "stopwords_path = \"stopwords.txt\"\n",
    "def load_stopwords(stopwords_path):\n",
    "    with open(stopwords_path, 'r', encoding='utf-8') as f:\n",
    "        return set(f.read().splitlines())\n",
    "stopwords = load_stopwords(stopwords_path)\n",
    "\n",
    "\n",
    "# 使用 jieba 進行中文分詞並過濾停用詞\n",
    "segmented_text = \" \".join([word for word in jieba.cut(text) if word not in stopwords])\n",
    "\n",
    "# 設置中文字體路徑\n",
    "font_path = r\"C:\\python\\程式練習\\vscode-synchronous\\爬新聞標題變成文字雲\\fonts\\TTF\\LXGWWenKaiMono-Regular.ttf\"\n",
    "#記得下載字體\n",
    "\n",
    "# 生成文字雲\n",
    "wordcloud = WordCloud(\n",
    "    font_path=font_path,\n",
    "    width=800,  # 調整輸出圖片的寬度\n",
    "    height=800, # 調整輸出圖片的高度\n",
    "    background_color='white',\n",
    "    mask=None,   # 使用預設的矩形\n",
    "    contour_width=2, # 設置輪廓線寬度\n",
    "    contour_color='gray', # 設置輪廓線顏色\n",
    "    min_font_size=10, # 設置最小字體大小\n",
    "    max_font_size=100, # 設置最大字體大小\n",
    "    prefer_horizontal=0.7, # 設置水平顯示的詞的比例\n",
    "    collocations=False # 避免重複單詞\n",
    ").generate(segmented_text)\n",
    "\n",
    "# 顯示文字雲\n",
    "plt.figure(figsize=(12, 16))\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "# 保存為圖片文件\n",
    "wordcloud.to_file(\"wordcloud.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
